# SPDX-License-Identifier: Apache-2.0

# arguments.py
from vllm.utils.arguments import (FlexibleArgumentParser, SortedHelpFormatter,
                                  StoreBoolean, deprecate_args,
                                  deprecate_kwargs,
                                  get_allowed_kwarg_only_overrides, identity,
                                  resolve_mm_processor_kwargs, supports_kw)
# cache.py
from vllm.utils.cache import CacheInfo, LRUCache, PyObjectCache
# constants.py
from vllm.utils.constants import (ALL_PINNED_SENTINEL,
                                  DEFAULT_MAX_NUM_BATCHED_TOKENS,
                                  MULTIMODAL_MODEL_MAX_NUM_BATCHED_TOKENS,
                                  POOLING_MODEL_MAX_NUM_BATCHED_TOKENS,
                                  STR_BACKEND_ENV_VAR,
                                  STR_DTYPE_TO_TORCH_DTYPE,
                                  STR_DUAL_CHUNK_FLASH_ATTN_VAL,
                                  STR_FLASH_ATTN_VAL, STR_FLASHINFER_ATTN_VAL,
                                  STR_INVALID_VAL,
                                  STR_NOT_IMPL_ENC_DEC_BACKEND,
                                  STR_NOT_IMPL_ENC_DEC_CHUNKED_PREFILL,
                                  STR_NOT_IMPL_ENC_DEC_ERR_STRS,
                                  STR_NOT_IMPL_ENC_DEC_LOGIT_SOFTCAP,
                                  STR_NOT_IMPL_ENC_DEC_LORA,
                                  STR_NOT_IMPL_ENC_DEC_MM,
                                  STR_NOT_IMPL_ENC_DEC_PP,
                                  STR_NOT_IMPL_ENC_DEC_PREFIX_CACHE,
                                  STR_NOT_IMPL_ENC_DEC_PROMPT_ADAPTER,
                                  STR_NOT_IMPL_ENC_DEC_SPEC_DEC,
                                  STR_NOT_IMPL_ENC_DEC_SWA,
                                  STR_ROCM_FLASH_ATTN_VAL,
                                  STR_TORCH_SDPA_ATTN_VAL,
                                  STR_XFORMERS_ATTN_VAL,
                                  TORCH_DTYPE_TO_NUMPY_DTYPE, Device, GB_bytes,
                                  GiB_bytes, LayerBlockType)
# device.py
from vllm.utils.device import (DeviceMemoryProfiler,
                               cuda_device_count_stateless,
                               cuda_get_device_properties, cuda_is_initialized,
                               current_stream, is_pin_memory_available,
                               is_uva_available)
# importing.py
from vllm.utils.importing import (PlaceholderModule, find_library,
                                  find_nccl_library,
                                  get_vllm_optional_dependencies,
                                  import_from_path, import_pynvml)
# misc.py
from vllm.utils.misc import (AtomicCounter, ClassRegistry, Counter, LazyDict,
                             LazyLoader, async_tensor_h2d, bind_kv_cache, cdiv,
                             chunk_list,
                             collect_from_async_generator,
                             create_kv_caches_with_random,
                             create_kv_caches_with_random_flash,
                             direct_register_custom_op,
                             enable_trace_function_call_for_thread,
                             flatten_2d_lists, full_groupby, get_cpu_memory,
                             get_cuda_view_from_cpu_tensor, get_dtype_size,
                             get_exception_traceback, get_kv_cache_torch_dtype,
                             get_max_shared_memory_bytes,
                             init_cached_hf_modules, is_in_doc_build,
                             is_list_of, is_torch_equal_or_newer, make_async,
                             make_ndarray_with_pad, make_tensor_with_pad,
                             merge_async_iterators, next_power_of_2,
                             random_uuid, resolve_obj_by_qualname, round_down,
                             round_up, run_method, run_once, set_ulimit,
                             sha256, supports_custom_op, supports_dynamo,
                             swap_dict_values, update_environment_variables,
                             vllm_lib, warn_for_unimplemented_methods,
                             weak_bind, weak_ref_tensor, weak_ref_tensors)
# network.py
from vllm.utils.network import (find_process_using_port,
                                get_distributed_init_method, get_ip,
                                get_open_port, get_open_zmq_inproc_path,
                                get_open_zmq_ipc_path, get_tcp_uri,
                                is_valid_ipv6_address, make_zmq_path,
                                make_zmq_socket, split_zmq_path,
                                zmq_socket_ctx)
# process.py
from vllm.utils.process import (get_mp_context, is_in_ray_actor,
                                kill_process_tree, maybe_force_spawn)
# profiling.py
from vllm.utils.profiling import (MemoryProfilingResult, MemorySnapshot,
                                  cprofile, cprofile_context, memory_profiling)

__all__ = [
    # arguments.py
    'FlexibleArgumentParser',
    'StoreBoolean',
    'SortedHelpFormatter',
    'identity',
    'deprecate_args',
    'supports_kw',
    'deprecate_kwargs',
    'resolve_mm_processor_kwargs',
    'get_allowed_kwarg_only_overrides',

    # cache.py
    'LRUCache',
    'CacheInfo',
    'PyObjectCache',

    # constants.py
    'DEFAULT_MAX_NUM_BATCHED_TOKENS',
    'POOLING_MODEL_MAX_NUM_BATCHED_TOKENS',
    'MULTIMODAL_MODEL_MAX_NUM_BATCHED_TOKENS',
    'GB_bytes',
    'GiB_bytes',
    'STR_DTYPE_TO_TORCH_DTYPE',
    'TORCH_DTYPE_TO_NUMPY_DTYPE',
    'STR_NOT_IMPL_ENC_DEC_SWA',
    'STR_NOT_IMPL_ENC_DEC_PREFIX_CACHE',
    'STR_NOT_IMPL_ENC_DEC_CHUNKED_PREFILL',
    'STR_NOT_IMPL_ENC_DEC_LOGIT_SOFTCAP',
    'STR_NOT_IMPL_ENC_DEC_LORA',
    'STR_NOT_IMPL_ENC_DEC_PP',
    'STR_NOT_IMPL_ENC_DEC_MM',
    'STR_NOT_IMPL_ENC_DEC_SPEC_DEC',
    'STR_NOT_IMPL_ENC_DEC_BACKEND',
    'STR_NOT_IMPL_ENC_DEC_PROMPT_ADAPTER',
    'STR_NOT_IMPL_ENC_DEC_ERR_STRS',
    'STR_BACKEND_ENV_VAR',
    'STR_FLASHINFER_ATTN_VAL',
    'STR_TORCH_SDPA_ATTN_VAL',
    'STR_ROCM_FLASH_ATTN_VAL',
    'STR_XFORMERS_ATTN_VAL',
    'STR_FLASH_ATTN_VAL',
    'STR_DUAL_CHUNK_FLASH_ATTN_VAL',
    'STR_INVALID_VAL',
    'ALL_PINNED_SENTINEL',
    'Device',
    'LayerBlockType',

    # device.py
    'current_stream',
    'cuda_device_count_stateless',
    'cuda_is_initialized',
    'cuda_get_device_properties',
    'is_pin_memory_available',
    'is_uva_available',
    'DeviceMemoryProfiler',

    # importing.py
    'import_from_path',
    'get_vllm_optional_dependencies',
    'PlaceholderModule',
    'find_library',
    'find_nccl_library',
    'import_pynvml',

    # misc.py
    'Counter',
    'get_max_shared_memory_bytes',
    'get_cpu_memory',
    'random_uuid',
    'make_async',
    'merge_async_iterators',
    'collect_from_async_generator',
    'update_environment_variables',
    'chunk_list',
    'cdiv',
    'next_power_of_2',
    'round_up',
    'round_down',
    'get_kv_cache_torch_dtype',
    'create_kv_caches_with_random_flash',
    'create_kv_caches_with_random',
    'make_ndarray_with_pad',
    'make_tensor_with_pad',
    'async_tensor_h2d',
    'get_dtype_size',
    'is_list_of',
    'flatten_2d_lists',
    'full_groupby',
    'init_cached_hf_modules',
    'enable_trace_function_call_for_thread',
    'weak_bind',
    'run_once',
    'supports_dynamo',
    'supports_custom_op',
    'AtomicCounter',
    'LazyDict',
    'ClassRegistry',
    'weak_ref_tensor',
    'weak_ref_tensors',
    'get_cuda_view_from_cpu_tensor',
    'is_in_doc_build',
    'vllm_lib',
    'direct_register_custom_op',
    'set_ulimit',
    'get_exception_traceback',
    'bind_kv_cache',
    'resolve_obj_by_qualname',
    'run_method',
    'sha256',
    'warn_for_unimplemented_methods',
    'LazyLoader',
    'swap_dict_values',
    'check_use_alibi',
    'is_torch_equal_or_newer',

    # network.py
    'get_ip',
    'is_valid_ipv6_address',
    'get_distributed_init_method',
    'get_tcp_uri',
    'get_open_zmq_ipc_path',
    'get_open_zmq_inproc_path',
    'get_open_port',
    'find_process_using_port',
    'split_zmq_path',
    'make_zmq_path',
    'make_zmq_socket',
    'zmq_socket_ctx',

    # process.py
    'is_in_ray_actor',
    'get_mp_context',
    'kill_process_tree',
    'maybe_force_spawn',

    # profiling.py
    'MemorySnapshot',
    'MemoryProfilingResult',
    'memory_profiling',
    'cprofile_context',
    'cprofile'
]
